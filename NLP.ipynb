{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном задании вам предстоит классифицировать тексты вакансии по классам. Вам даны два файла:\n",
    "\n",
    "train.csv - тексты и классы test.csv - тексты по которым нужно сделать предсказания\n",
    "\n",
    "В обоих файлах данные по файлу хранятся в одной строке. В файле с текстами в начале строки находится идентификатор текста. Разделитель - ; Ваша задача создать модель, которая будет определять класс вакансии по тексту вакансии.\n",
    "Метрика - ROC-AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "import pickle\n",
    "import re\n",
    "\n",
    "from langdetect import detect\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "\n",
    "import pymystem3\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold,  train_test_split\n",
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "import warnings\n",
    "\n",
    "pd.options.display.max_rows = 200\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train  = pd.read_csv('train.csv', sep=';')\n",
    "df_test  = pd.read_csv('test.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Размер тренировочной выборки: (31063, 4) \n",
      " Размер тестовой выборки: (31064, 3) \n",
      " Размер общей выборки: (62127, 4) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_train['sample'] = 'train'\n",
    "df_test['sample'] = 'test'\n",
    "df = df_test.append(df_train).reset_index(drop=True)\n",
    "print(' Размер тренировочной выборки:', df_train.shape, '\\n',\n",
    "    'Размер тестовой выборки:', df_test.shape, '\\n',\n",
    "    'Размер общей выборки:', df.shape, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sample</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31063</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;В крупную компанию по организации и...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31064</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31065</td>\n",
       "      <td>&lt;p&gt; &lt;/p&gt; &lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; ...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31066</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Обязанности:&lt;/strong&gt;&lt;/p&gt; &lt;ul&gt; &lt;li&gt;...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31067</td>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Вакансия СРОЧНАЯ!&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text sample  target\n",
       "0  31063  <p><strong>В крупную компанию по организации и...   test     NaN\n",
       "1  31064  <p><strong>Обязанности:</strong></p> <ul> <li>...   test     NaN\n",
       "2  31065  <p> </p> <p><strong>Обязанности:</strong></p> ...   test     NaN\n",
       "3  31066  <p><strong>Обязанности:</strong></p> <ul> <li>...   test     NaN\n",
       "4  31067  <p><strong>Вакансия СРОЧНАЯ!</strong></p> <p><...   test     NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA (exploratory data analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    В текстах вакансий присутствует html разметка, удалим её при помощи BeautifulSoup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].map(lambda x: BeautifulSoup(x).text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sample</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31063</td>\n",
       "      <td>В крупную компанию по организации и приготовле...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31064</td>\n",
       "      <td>Обязанности:  Обеспечение необходимой функцион...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31065</td>\n",
       "      <td>Обязанности:  отгрузка и прием товара со скл...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31066</td>\n",
       "      <td>Обязанности:  приготовление холодных и горячих...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31067</td>\n",
       "      <td>Вакансия СРОЧНАЯ! Внимание! Просьба подробно и...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id                                               text sample  target\n",
       "0  31063  В крупную компанию по организации и приготовле...   test     NaN\n",
       "1  31064  Обязанности:  Обеспечение необходимой функцион...   test     NaN\n",
       "2  31065    Обязанности:  отгрузка и прием товара со скл...   test     NaN\n",
       "3  31066  Обязанности:  приготовление холодных и горячих...   test     NaN\n",
       "4  31067  Вакансия СРОЧНАЯ! Внимание! Просьба подробно и...   test     NaN"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Данные будем готовить двумя методами - созданием словаря Word2Vec и перевод вакансий в это пространство: \n",
    "    если слово есть в вакансии - прибавим его к вектору \"вакансии\". Потом разделим полученный вектор на сумму слов.     \n",
    "    Делаем подготовку данных для словаря Word2Vec с использованием морфологического анализа (библиотека pymystem3). Напишем функцию, которая будет разбивать описание вакансиий на слова, проводить их морфологический анализ \n",
    "    (определение части речи и начальной формы слова), если слово относится к глаголу, существительному или\n",
    "    прилагательному, то вернем его начальную форму. Составим список слов вакансии и вернем этот список\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "word_dict = {}\n",
    "def normalize(text):\n",
    "    output = []\n",
    "    sentence = re.sub(r'[^\\w]', ' ', text).split()\n",
    "    if detect(text) != 'ru':\n",
    "        output.append(sentence)\n",
    "    else:\n",
    "        words = []\n",
    "        for new_word in sentence:\n",
    "            if len(new_word)>1:\n",
    "                if word_dict.get(new_word):\n",
    "                    words.append(word_dict[new_word])\n",
    "                else:\n",
    "                    token = m.analyze(new_word)\n",
    "                    if token[0].get('analysis'):\n",
    "                        word = token[0]['analysis'][0]['lex']\n",
    "                        pos = token[0]['analysis'][0]['gr']\n",
    "                        if pos[0] in ['A', 'S', 'V']:\n",
    "                            words.append(word)\n",
    "                            word_dict[new_word] = word\n",
    "        output.append(list(set(words)))\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ced8db9e75940638cb2fbd31097a606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=62127.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "all_sentences = []\n",
    "for text in tqdm(df['text']):\n",
    "    all_sentences.extend(normalize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62127"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Сохраним данные в pickle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"all_sentences.txt\", \"wb\") as fp:\n",
    "    pickle.dump(all_sentences, fp)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Возможно потребуется\n",
    "with open(\"all_sentences.txt\", \"rb\") as fp:   # Unpickling\n",
    "    all_sentences = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Созданим собственный словарь в Word2Vec из слов в наших вакансиях (начальные формы существительных, глаголов и прилагательных)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 19s, sys: 581 ms, total: 1min 20s\n",
      "Wall time: 31.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# список параметров, которые можно менять по вашему желанию\n",
    "num_features = 50  # итоговая размерность вектора каждого слова\n",
    "min_word_count = 5  # минимальная частотность слова, чтобы оно попало в модель\n",
    "num_workers = 5     # количество ядер вашего процессора, чтоб запустить обучение в несколько потоков\n",
    "context = 5         # размер окна \n",
    "downsampling = 1e-3 # внутренняя метрика модели\n",
    "\n",
    "my_model = Word2Vec(all_sentences, workers=num_workers, size=num_features,\n",
    "                 min_count=min_word_count, window=context, sample=downsampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Оценим результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер словаря(корпуса) - 5223562 Размерность вектора слов -  50\n"
     ]
    }
   ],
   "source": [
    "print('Размер словаря(корпуса) -', my_model.corpus_total_words, \n",
    "      'Размерность вектора слов - ', my_model.vector_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    \"Заморозим\" наш словарь векторов слов для дальнейшего использования"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Время магии. Составляем общий ветор слов в нашей вакансии, приведённый к количеству слов в вакансии:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b66840808d44ac83d9d9ff71dee49b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=62127.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "index2word_set = list(set(my_model.wv.index2word))\n",
    "\n",
    "w2v_vectors = []\n",
    "for sentense in tqdm(all_sentences):\n",
    "    text_vec = np.zeros((my_model.vector_size), dtype=\"float32\")\n",
    "    n_words = 0\n",
    "    for word in sentense:\n",
    "        if word in index2word_set:\n",
    "            n_words = n_words + 1\n",
    "            text_vec = np.add(text_vec, my_model[word])\n",
    "    if n_words != 0:\n",
    "        text_vec /= n_words\n",
    "    w2v_vectors.append(text_vec)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Создадим из полученных векторов новый DataFrame, проведем его нормирование через \n",
    "    StandartScale() и добавим к нашим данным. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w2v_vectors = pd.DataFrame(w2v_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_w2v = pd.concat([df, df_w2v_vectors], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>sample</th>\n",
       "      <th>target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>31063</td>\n",
       "      <td>В крупную компанию по организации и приготовле...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009692</td>\n",
       "      <td>-0.012096</td>\n",
       "      <td>0.011477</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>0.034324</td>\n",
       "      <td>0.013835</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001376</td>\n",
       "      <td>-0.049844</td>\n",
       "      <td>0.007026</td>\n",
       "      <td>-0.063618</td>\n",
       "      <td>-0.015122</td>\n",
       "      <td>0.019125</td>\n",
       "      <td>0.013729</td>\n",
       "      <td>0.045449</td>\n",
       "      <td>-0.058340</td>\n",
       "      <td>-0.002166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>31064</td>\n",
       "      <td>Обязанности:  Обеспечение необходимой функцион...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.027645</td>\n",
       "      <td>-0.006044</td>\n",
       "      <td>0.018141</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>-0.013684</td>\n",
       "      <td>0.024177</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000145</td>\n",
       "      <td>0.011921</td>\n",
       "      <td>-0.015817</td>\n",
       "      <td>-0.000845</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.002328</td>\n",
       "      <td>0.006252</td>\n",
       "      <td>-0.007417</td>\n",
       "      <td>-0.010404</td>\n",
       "      <td>-0.035867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31065</td>\n",
       "      <td>Обязанности:  отгрузка и прием товара со скл...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025459</td>\n",
       "      <td>-0.040618</td>\n",
       "      <td>-0.031368</td>\n",
       "      <td>-0.002854</td>\n",
       "      <td>0.016386</td>\n",
       "      <td>0.041660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018855</td>\n",
       "      <td>-0.013222</td>\n",
       "      <td>0.055444</td>\n",
       "      <td>-0.060059</td>\n",
       "      <td>-0.007496</td>\n",
       "      <td>0.042994</td>\n",
       "      <td>-0.027436</td>\n",
       "      <td>0.024707</td>\n",
       "      <td>-0.038612</td>\n",
       "      <td>-0.030771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>31066</td>\n",
       "      <td>Обязанности:  приготовление холодных и горячих...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023435</td>\n",
       "      <td>-0.028566</td>\n",
       "      <td>-0.035077</td>\n",
       "      <td>0.068286</td>\n",
       "      <td>0.004282</td>\n",
       "      <td>-0.019079</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004231</td>\n",
       "      <td>-0.039630</td>\n",
       "      <td>0.005180</td>\n",
       "      <td>-0.047777</td>\n",
       "      <td>-0.051409</td>\n",
       "      <td>0.056020</td>\n",
       "      <td>-0.016946</td>\n",
       "      <td>0.060479</td>\n",
       "      <td>-0.041780</td>\n",
       "      <td>0.006688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31067</td>\n",
       "      <td>Вакансия СРОЧНАЯ! Внимание! Просьба подробно и...</td>\n",
       "      <td>test</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009003</td>\n",
       "      <td>0.015710</td>\n",
       "      <td>-0.006751</td>\n",
       "      <td>-0.007007</td>\n",
       "      <td>0.007899</td>\n",
       "      <td>0.010307</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035466</td>\n",
       "      <td>0.000730</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>-0.001965</td>\n",
       "      <td>-0.006512</td>\n",
       "      <td>-0.003810</td>\n",
       "      <td>0.012426</td>\n",
       "      <td>0.016349</td>\n",
       "      <td>-0.024242</td>\n",
       "      <td>-0.032836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62122</th>\n",
       "      <td>31058</td>\n",
       "      <td>Обязанности:  Создание атмосферы гостеприимств...</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.041570</td>\n",
       "      <td>-0.081356</td>\n",
       "      <td>-0.066499</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.004897</td>\n",
       "      <td>0.051060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.035452</td>\n",
       "      <td>0.028755</td>\n",
       "      <td>-0.010448</td>\n",
       "      <td>0.017975</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.040819</td>\n",
       "      <td>0.047780</td>\n",
       "      <td>0.015575</td>\n",
       "      <td>-0.099956</td>\n",
       "      <td>-0.000112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62123</th>\n",
       "      <td>31059</td>\n",
       "      <td>Обязанности: ведение бухгалтерского, налоговог...</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.028025</td>\n",
       "      <td>0.006941</td>\n",
       "      <td>0.024264</td>\n",
       "      <td>0.020101</td>\n",
       "      <td>-0.003867</td>\n",
       "      <td>-0.021826</td>\n",
       "      <td>...</td>\n",
       "      <td>0.034610</td>\n",
       "      <td>-0.071575</td>\n",
       "      <td>0.046674</td>\n",
       "      <td>-0.082472</td>\n",
       "      <td>-0.016335</td>\n",
       "      <td>0.062519</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>-0.006985</td>\n",
       "      <td>-0.007888</td>\n",
       "      <td>-0.012490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62124</th>\n",
       "      <td>31060</td>\n",
       "      <td>В жилой дом, расположенный у станции метро \"Зв...</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.014316</td>\n",
       "      <td>-0.029265</td>\n",
       "      <td>0.015154</td>\n",
       "      <td>0.041256</td>\n",
       "      <td>0.001097</td>\n",
       "      <td>-0.022268</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.032398</td>\n",
       "      <td>-0.047645</td>\n",
       "      <td>0.015745</td>\n",
       "      <td>-0.053868</td>\n",
       "      <td>-0.046522</td>\n",
       "      <td>0.040444</td>\n",
       "      <td>-0.023134</td>\n",
       "      <td>0.075914</td>\n",
       "      <td>-0.036307</td>\n",
       "      <td>-0.006032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62125</th>\n",
       "      <td>31061</td>\n",
       "      <td>В нашу дружную команду требуется архитектор-ди...</td>\n",
       "      <td>train</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.032346</td>\n",
       "      <td>-0.038017</td>\n",
       "      <td>-0.001400</td>\n",
       "      <td>0.029337</td>\n",
       "      <td>0.011012</td>\n",
       "      <td>0.016577</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.015414</td>\n",
       "      <td>-0.052418</td>\n",
       "      <td>-0.050502</td>\n",
       "      <td>-0.034396</td>\n",
       "      <td>-0.019782</td>\n",
       "      <td>-0.018623</td>\n",
       "      <td>-0.010110</td>\n",
       "      <td>-0.008327</td>\n",
       "      <td>-0.020328</td>\n",
       "      <td>-0.009507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62126</th>\n",
       "      <td>31062</td>\n",
       "      <td>Обязанности:  Осуществлять работу по планирова...</td>\n",
       "      <td>train</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.013892</td>\n",
       "      <td>0.021038</td>\n",
       "      <td>-0.026685</td>\n",
       "      <td>0.030065</td>\n",
       "      <td>0.048693</td>\n",
       "      <td>0.020971</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>-0.003989</td>\n",
       "      <td>0.054401</td>\n",
       "      <td>-0.045731</td>\n",
       "      <td>-0.006630</td>\n",
       "      <td>-0.008371</td>\n",
       "      <td>-0.037880</td>\n",
       "      <td>0.028031</td>\n",
       "      <td>-0.018140</td>\n",
       "      <td>-0.030377</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62127 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                                               text sample  \\\n",
       "0      31063  В крупную компанию по организации и приготовле...   test   \n",
       "1      31064  Обязанности:  Обеспечение необходимой функцион...   test   \n",
       "2      31065    Обязанности:  отгрузка и прием товара со скл...   test   \n",
       "3      31066  Обязанности:  приготовление холодных и горячих...   test   \n",
       "4      31067  Вакансия СРОЧНАЯ! Внимание! Просьба подробно и...   test   \n",
       "...      ...                                                ...    ...   \n",
       "62122  31058  Обязанности:  Создание атмосферы гостеприимств...  train   \n",
       "62123  31059  Обязанности: ведение бухгалтерского, налоговог...  train   \n",
       "62124  31060  В жилой дом, расположенный у станции метро \"Зв...  train   \n",
       "62125  31061  В нашу дружную команду требуется архитектор-ди...  train   \n",
       "62126  31062  Обязанности:  Осуществлять работу по планирова...  train   \n",
       "\n",
       "       target         0         1         2         3         4         5  \\\n",
       "0         NaN -0.009692 -0.012096  0.011477  0.021942  0.034324  0.013835   \n",
       "1         NaN -0.027645 -0.006044  0.018141  0.000194 -0.013684  0.024177   \n",
       "2         NaN  0.025459 -0.040618 -0.031368 -0.002854  0.016386  0.041660   \n",
       "3         NaN -0.023435 -0.028566 -0.035077  0.068286  0.004282 -0.019079   \n",
       "4         NaN -0.009003  0.015710 -0.006751 -0.007007  0.007899  0.010307   \n",
       "...       ...       ...       ...       ...       ...       ...       ...   \n",
       "62122     1.0 -0.041570 -0.081356 -0.066499  0.014493  0.004897  0.051060   \n",
       "62123     1.0  0.028025  0.006941  0.024264  0.020101 -0.003867 -0.021826   \n",
       "62124     0.0 -0.014316 -0.029265  0.015154  0.041256  0.001097 -0.022268   \n",
       "62125     0.0 -0.032346 -0.038017 -0.001400  0.029337  0.011012  0.016577   \n",
       "62126     1.0 -0.013892  0.021038 -0.026685  0.030065  0.048693  0.020971   \n",
       "\n",
       "       ...        40        41        42        43        44        45  \\\n",
       "0      ... -0.001376 -0.049844  0.007026 -0.063618 -0.015122  0.019125   \n",
       "1      ... -0.000145  0.011921 -0.015817 -0.000845  0.000322  0.002328   \n",
       "2      ... -0.018855 -0.013222  0.055444 -0.060059 -0.007496  0.042994   \n",
       "3      ...  0.004231 -0.039630  0.005180 -0.047777 -0.051409  0.056020   \n",
       "4      ... -0.035466  0.000730  0.006932 -0.001965 -0.006512 -0.003810   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "62122  ... -0.035452  0.028755 -0.010448  0.017975  0.000189  0.040819   \n",
       "62123  ...  0.034610 -0.071575  0.046674 -0.082472 -0.016335  0.062519   \n",
       "62124  ... -0.032398 -0.047645  0.015745 -0.053868 -0.046522  0.040444   \n",
       "62125  ... -0.015414 -0.052418 -0.050502 -0.034396 -0.019782 -0.018623   \n",
       "62126  ...  0.000226 -0.003989  0.054401 -0.045731 -0.006630 -0.008371   \n",
       "\n",
       "             46        47        48        49  \n",
       "0      0.013729  0.045449 -0.058340 -0.002166  \n",
       "1      0.006252 -0.007417 -0.010404 -0.035867  \n",
       "2     -0.027436  0.024707 -0.038612 -0.030771  \n",
       "3     -0.016946  0.060479 -0.041780  0.006688  \n",
       "4      0.012426  0.016349 -0.024242 -0.032836  \n",
       "...         ...       ...       ...       ...  \n",
       "62122  0.047780  0.015575 -0.099956 -0.000112  \n",
       "62123  0.002847 -0.006985 -0.007888 -0.012490  \n",
       "62124 -0.023134  0.075914 -0.036307 -0.006032  \n",
       "62125 -0.010110 -0.008327 -0.020328 -0.009507  \n",
       "62126 -0.037880  0.028031 -0.018140 -0.030377  \n",
       "\n",
       "[62127 rows x 54 columns]"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_w2v.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"df_new_w2v.txt\", \"wb\") as fp:\n",
    "    pickle.dump(df_new_w2v, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Займемся подбором модели:\n",
    "    1. Разделим обратно данные:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_new_w2v[df_new_w2v['sample']=='train']\n",
    "df_train = df_train.drop([ 'text', 'sample', 'id'], axis = 1)\n",
    "\n",
    "target = df_train['target']\n",
    "df_train = df_train.drop(['target'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_test = df_new_w2v[df_new_w2v['sample']=='test']\n",
    "test_id = df_new_test['id']\n",
    "df_new_test = df_new_test.drop(['text', 'target','sample', 'id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Отделим валидационную выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, target, \n",
    "                                                    test_size=0.2, random_state=123) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.  По заданию у нас метрика ROC-AUC, а обучать сначала будем градиентный бустинг\n",
    "    3.1 Созданим pipeline и начнем подбор параметров с помощью RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypipeline_gb = Pipeline([\n",
    "    ('gb', GradientBoostingClassifier())\n",
    "])\n",
    "param_grid_gb = { 'gb__max_depth': range(17, 30),\n",
    "                  'gb__n_estimators': range(150,200),\n",
    "                  'gb__subsample':[0.3,0.5,0.7,0.9],\n",
    "                  'gb__min_samples_leaf': range(1,10, 2),\n",
    "                  'gb__min_samples_split': range(2, 21, 2),\n",
    "                  'gb__min_impurity_decrease':[0, 0.000001],\n",
    "                  'gb__learning_rate': [0.001, 0.01, 0.05, 0.1, 0.5, 0.9]\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "hyper_search_gb = RandomizedSearchCV(mypipeline_gb, param_grid_gb, n_iter=5, scoring='roc_auc', \n",
    "                                  cv=cv, n_jobs=4, refit=True, random_state=47,\n",
    "                                  verbose=3)\n",
    "hyper_search_gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.2 Посмотрим на лучшее значение ROC-AUC, а также на влияние гиперпараметров на его значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('GBC', hyper_search_gb.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(hyper_search_gb.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_gb = pd.DataFrame(hyper_search_gb.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_search_gb.sort_values(by='mean_test_score',ascending=False).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.3 Параметры модели выбраны, обучим её на всех данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(subsample= 0.7, n_estimators=177, min_samples_split=16, min_samples_leaf= 7, \n",
    "                                      min_impurity_decrease= 1e-06, max_depth=19, learning_rate=0.1)\n",
    "gb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.4 Проверим данные на отложенной (валидационной) выборке:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pridict = gb.predict(X_test)\n",
    "roc_auc_score(y_test, pridict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.5 Ну и сделаем предсказание"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = gb.predict_proba(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(test_id, predict[1]), columns=['id','target']).to_csv('predict_26-02.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     Теперь попробуем создать матрицу 𝑇𝐹∗𝐼𝐷𝐹 для всех наших вакансий. Напишем функцию, \n",
    "     похожую на предыдущую, но мы будем получать список строк вакансий, а не список \n",
    "     списков вакансий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Mystem()\n",
    "word_dict = {}\n",
    "\n",
    "def normalize2(text):\n",
    "    sentence = re.sub(r'[^\\w]', ' ', text).split()\n",
    "    words = []\n",
    "    if detect(text) != 'ru':\n",
    "        words.append(re.sub(r'[^\\w]', ' ', text))\n",
    "    else:\n",
    "        k = ''\n",
    "        for new_word in sentence:\n",
    "            if len(new_word)>1:\n",
    "                if word_dict.get(new_word):\n",
    "                    words.append(word_dict[new_word])  \n",
    "                    k = k+word+' '\n",
    "                else:\n",
    "                    token = m.analyze(new_word)\n",
    "                    if token[0].get('analysis'):\n",
    "                        word = token[0]['analysis'][0]['lex']\n",
    "                        pos = token[0]['analysis'][0]['gr']\n",
    "                        if pos[0] in ['A', 'S', 'V']:\n",
    "                            k = k+word+' '\n",
    "        words.append(k)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Применим функцию и сокраним всё в Pikcle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7a092332e6c4873a9451de571aeaba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=62127.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "new_sentences = []\n",
    "for text in tqdm(df['text']):\n",
    "    new_sentences.extend(normalize2(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62127"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(new_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"new_sentences.txt\", \"wb\") as fp:\n",
    "    pickle.dump(new_sentences, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Обучим TfidfVectorizer на всех наших данных:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(sublinear_tf = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
       "                input='content', lowercase=True, max_df=1.0, max_features=None,\n",
       "                min_df=1, ngram_range=(1, 1), norm='l2', preprocessor=None,\n",
       "                smooth_idf=True, stop_words=None, strip_accents=None,\n",
       "                sublinear_tf=True, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                tokenizer=None, use_idf=True, vocabulary=None)"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.fit(new_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    И сделаем 𝑇𝐹∗𝐼𝐷𝐹 матрицу наших предложений (отделно для тренировочной и тестовой выборок)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lemmatized = df[df['sample']=='train']\n",
    "test_lemmatized = df[df['sample']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tfidf = tfidf.transform(train_lemmatized['text'])\n",
    "test_tfidf = tfidf.transform(test_lemmatized['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_target = train_lemmatized['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_tfidf, train_target, \n",
    "                                                    test_size=0.2, random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypipeline_lr = Pipeline([\n",
    "    ('lr', LogisticRegression())])\n",
    "\n",
    "param_grid_lr = { 'lr__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                  'lr__tol': [0.00001, 0.0001, 0.001],\n",
    "                  'lr__solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                  'lr__C' : [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 0.0, 1.0]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 tasks      | elapsed:    2.4s\n"
     ]
    }
   ],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "hyper_search_lr = RandomizedSearchCV(mypipeline_lr, param_grid_lr, n_iter=100, scoring='roc_auc', \n",
    "                                  cv=cv, n_jobs=4, refit=True, random_state=47,\n",
    "                                  verbose=5)\n",
    "hyper_search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRes 0.9788307449330185\n",
      "{'lr__tol': 0.001, 'lr__solver': 'saga', 'lr__penalty': 'none', 'lr__C': 0.0}\n"
     ]
    }
   ],
   "source": [
    "print('LogRes', hyper_search_lr.best_score_)\n",
    "print(hyper_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(tol=0.001, solver='saga', penalty = 'none', C =0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='none',\n",
       "                   random_state=None, solver='saga', tol=0.001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(train_tfidf, train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr = lr.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tfidf = tfidf.transform(train_tfidf)\n",
    "df_test_tfidf = tfidf.transform(test_tfidf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_test = df_new[df_new['sample']=='test']\n",
    "test_id = df_new_test['id']\n",
    "df_new_test = df_new_test.drop(['text', 'target','sample', 'id'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    2. Отделим валидационную выборку"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, target, \n",
    "                                                    test_size=0.2, random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(test_id, predict[1]), columns=['id','target']).to_csv('predict_26-02.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3.4 Попробуем теперь модель логистической регрессии (все шаги аналогичны):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_new[df_new['sample']=='train']\n",
    "df_train = df_train.drop([ 'lang', 'text', 'sample', 'id'], axis = 1)\n",
    "\n",
    "target = df_train['target']\n",
    "df_train = df_train.drop(['target'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.048534</td>\n",
       "      <td>0.047571</td>\n",
       "      <td>0.058687</td>\n",
       "      <td>-0.018591</td>\n",
       "      <td>0.046081</td>\n",
       "      <td>-0.010539</td>\n",
       "      <td>-0.029725</td>\n",
       "      <td>-0.036074</td>\n",
       "      <td>0.022760</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.064167</td>\n",
       "      <td>0.068819</td>\n",
       "      <td>-0.093172</td>\n",
       "      <td>0.012321</td>\n",
       "      <td>-0.014153</td>\n",
       "      <td>-0.068234</td>\n",
       "      <td>-0.007546</td>\n",
       "      <td>-0.033890</td>\n",
       "      <td>-0.064652</td>\n",
       "      <td>0.016229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.036070</td>\n",
       "      <td>0.025835</td>\n",
       "      <td>0.032085</td>\n",
       "      <td>0.032439</td>\n",
       "      <td>0.045227</td>\n",
       "      <td>-0.013449</td>\n",
       "      <td>0.018120</td>\n",
       "      <td>-0.052522</td>\n",
       "      <td>-0.028263</td>\n",
       "      <td>-0.009837</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.050580</td>\n",
       "      <td>0.064305</td>\n",
       "      <td>-0.057780</td>\n",
       "      <td>0.090739</td>\n",
       "      <td>-0.037933</td>\n",
       "      <td>-0.014616</td>\n",
       "      <td>-0.029467</td>\n",
       "      <td>-0.029742</td>\n",
       "      <td>0.054784</td>\n",
       "      <td>-0.060642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.010065</td>\n",
       "      <td>0.058150</td>\n",
       "      <td>0.044352</td>\n",
       "      <td>0.046919</td>\n",
       "      <td>-0.052414</td>\n",
       "      <td>-0.029630</td>\n",
       "      <td>0.006786</td>\n",
       "      <td>-0.032574</td>\n",
       "      <td>0.006919</td>\n",
       "      <td>-0.036406</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.034074</td>\n",
       "      <td>0.029135</td>\n",
       "      <td>-0.020393</td>\n",
       "      <td>0.018462</td>\n",
       "      <td>-0.016672</td>\n",
       "      <td>-0.059624</td>\n",
       "      <td>0.047566</td>\n",
       "      <td>0.005071</td>\n",
       "      <td>-0.058323</td>\n",
       "      <td>0.006377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.026657</td>\n",
       "      <td>0.013812</td>\n",
       "      <td>0.025367</td>\n",
       "      <td>0.013324</td>\n",
       "      <td>-0.062354</td>\n",
       "      <td>0.098799</td>\n",
       "      <td>-0.017324</td>\n",
       "      <td>0.012411</td>\n",
       "      <td>0.000881</td>\n",
       "      <td>-0.008061</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.049376</td>\n",
       "      <td>0.051521</td>\n",
       "      <td>-0.136965</td>\n",
       "      <td>0.012129</td>\n",
       "      <td>0.028002</td>\n",
       "      <td>-0.080966</td>\n",
       "      <td>0.028812</td>\n",
       "      <td>0.003304</td>\n",
       "      <td>-0.066382</td>\n",
       "      <td>0.031387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.022742</td>\n",
       "      <td>-0.010745</td>\n",
       "      <td>0.006650</td>\n",
       "      <td>0.005026</td>\n",
       "      <td>0.034022</td>\n",
       "      <td>-0.011833</td>\n",
       "      <td>0.019907</td>\n",
       "      <td>-0.010415</td>\n",
       "      <td>-0.007886</td>\n",
       "      <td>-0.011825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>0.046487</td>\n",
       "      <td>-0.023325</td>\n",
       "      <td>0.038159</td>\n",
       "      <td>-0.006442</td>\n",
       "      <td>0.001059</td>\n",
       "      <td>0.007444</td>\n",
       "      <td>-0.024818</td>\n",
       "      <td>0.021036</td>\n",
       "      <td>-0.035649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31059</th>\n",
       "      <td>0.010257</td>\n",
       "      <td>-0.053726</td>\n",
       "      <td>0.075761</td>\n",
       "      <td>0.043358</td>\n",
       "      <td>-0.086408</td>\n",
       "      <td>0.053989</td>\n",
       "      <td>0.020136</td>\n",
       "      <td>0.037576</td>\n",
       "      <td>0.049897</td>\n",
       "      <td>0.080496</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013137</td>\n",
       "      <td>0.040359</td>\n",
       "      <td>-0.072743</td>\n",
       "      <td>-0.021994</td>\n",
       "      <td>-0.015918</td>\n",
       "      <td>-0.087914</td>\n",
       "      <td>-0.026765</td>\n",
       "      <td>0.001961</td>\n",
       "      <td>-0.097647</td>\n",
       "      <td>0.009055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31060</th>\n",
       "      <td>0.076382</td>\n",
       "      <td>0.034959</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>-0.018965</td>\n",
       "      <td>0.100007</td>\n",
       "      <td>0.079176</td>\n",
       "      <td>0.040875</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.034222</td>\n",
       "      <td>-0.025086</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062635</td>\n",
       "      <td>-0.004796</td>\n",
       "      <td>-0.031663</td>\n",
       "      <td>0.014627</td>\n",
       "      <td>-0.012913</td>\n",
       "      <td>0.024049</td>\n",
       "      <td>0.023255</td>\n",
       "      <td>-0.002590</td>\n",
       "      <td>-0.007980</td>\n",
       "      <td>-0.034236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31061</th>\n",
       "      <td>-0.002675</td>\n",
       "      <td>0.046696</td>\n",
       "      <td>0.032751</td>\n",
       "      <td>0.025726</td>\n",
       "      <td>-0.067436</td>\n",
       "      <td>-0.057088</td>\n",
       "      <td>-0.013116</td>\n",
       "      <td>0.036461</td>\n",
       "      <td>0.020919</td>\n",
       "      <td>0.063970</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.029849</td>\n",
       "      <td>0.039908</td>\n",
       "      <td>-0.030530</td>\n",
       "      <td>-0.052518</td>\n",
       "      <td>0.090020</td>\n",
       "      <td>-0.057650</td>\n",
       "      <td>0.034707</td>\n",
       "      <td>0.017355</td>\n",
       "      <td>-0.093878</td>\n",
       "      <td>0.049013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31062</th>\n",
       "      <td>0.067936</td>\n",
       "      <td>0.022239</td>\n",
       "      <td>-0.006599</td>\n",
       "      <td>-0.029971</td>\n",
       "      <td>0.056214</td>\n",
       "      <td>0.014212</td>\n",
       "      <td>0.028402</td>\n",
       "      <td>0.007138</td>\n",
       "      <td>0.017489</td>\n",
       "      <td>-0.011437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012897</td>\n",
       "      <td>0.033814</td>\n",
       "      <td>-0.030455</td>\n",
       "      <td>0.044858</td>\n",
       "      <td>0.018468</td>\n",
       "      <td>0.025513</td>\n",
       "      <td>0.006351</td>\n",
       "      <td>-0.043535</td>\n",
       "      <td>0.044649</td>\n",
       "      <td>-0.066918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31063</th>\n",
       "      <td>0.033080</td>\n",
       "      <td>-0.053928</td>\n",
       "      <td>0.040333</td>\n",
       "      <td>-0.044701</td>\n",
       "      <td>0.020121</td>\n",
       "      <td>-0.003086</td>\n",
       "      <td>0.087003</td>\n",
       "      <td>0.019693</td>\n",
       "      <td>0.153595</td>\n",
       "      <td>0.039646</td>\n",
       "      <td>...</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>0.042990</td>\n",
       "      <td>-0.033907</td>\n",
       "      <td>-0.042156</td>\n",
       "      <td>-0.008344</td>\n",
       "      <td>-0.043792</td>\n",
       "      <td>0.075405</td>\n",
       "      <td>-0.025435</td>\n",
       "      <td>0.031378</td>\n",
       "      <td>-0.029673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31064 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1         2         3         4         5         6  \\\n",
       "0      0.020300  0.048534  0.047571  0.058687 -0.018591  0.046081 -0.010539   \n",
       "1     -0.036070  0.025835  0.032085  0.032439  0.045227 -0.013449  0.018120   \n",
       "2      0.010065  0.058150  0.044352  0.046919 -0.052414 -0.029630  0.006786   \n",
       "3     -0.026657  0.013812  0.025367  0.013324 -0.062354  0.098799 -0.017324   \n",
       "4      0.022742 -0.010745  0.006650  0.005026  0.034022 -0.011833  0.019907   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "31059  0.010257 -0.053726  0.075761  0.043358 -0.086408  0.053989  0.020136   \n",
       "31060  0.076382  0.034959  0.007231 -0.018965  0.100007  0.079176  0.040875   \n",
       "31061 -0.002675  0.046696  0.032751  0.025726 -0.067436 -0.057088 -0.013116   \n",
       "31062  0.067936  0.022239 -0.006599 -0.029971  0.056214  0.014212  0.028402   \n",
       "31063  0.033080 -0.053928  0.040333 -0.044701  0.020121 -0.003086  0.087003   \n",
       "\n",
       "              7         8         9  ...        40        41        42  \\\n",
       "0     -0.029725 -0.036074  0.022760  ... -0.064167  0.068819 -0.093172   \n",
       "1     -0.052522 -0.028263 -0.009837  ... -0.050580  0.064305 -0.057780   \n",
       "2     -0.032574  0.006919 -0.036406  ... -0.034074  0.029135 -0.020393   \n",
       "3      0.012411  0.000881 -0.008061  ... -0.049376  0.051521 -0.136965   \n",
       "4     -0.010415 -0.007886 -0.011825  ...  0.000592  0.046487 -0.023325   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "31059  0.037576  0.049897  0.080496  ... -0.013137  0.040359 -0.072743   \n",
       "31060  0.014493  0.034222 -0.025086  ...  0.062635 -0.004796 -0.031663   \n",
       "31061  0.036461  0.020919  0.063970  ... -0.029849  0.039908 -0.030530   \n",
       "31062  0.007138  0.017489 -0.011437  ...  0.012897  0.033814 -0.030455   \n",
       "31063  0.019693  0.153595  0.039646  ...  0.027130  0.042990 -0.033907   \n",
       "\n",
       "             43        44        45        46        47        48        49  \n",
       "0      0.012321 -0.014153 -0.068234 -0.007546 -0.033890 -0.064652  0.016229  \n",
       "1      0.090739 -0.037933 -0.014616 -0.029467 -0.029742  0.054784 -0.060642  \n",
       "2      0.018462 -0.016672 -0.059624  0.047566  0.005071 -0.058323  0.006377  \n",
       "3      0.012129  0.028002 -0.080966  0.028812  0.003304 -0.066382  0.031387  \n",
       "4      0.038159 -0.006442  0.001059  0.007444 -0.024818  0.021036 -0.035649  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "31059 -0.021994 -0.015918 -0.087914 -0.026765  0.001961 -0.097647  0.009055  \n",
       "31060  0.014627 -0.012913  0.024049  0.023255 -0.002590 -0.007980 -0.034236  \n",
       "31061 -0.052518  0.090020 -0.057650  0.034707  0.017355 -0.093878  0.049013  \n",
       "31062  0.044858  0.018468  0.025513  0.006351 -0.043535  0.044649 -0.066918  \n",
       "31063 -0.042156 -0.008344 -0.043792  0.075405 -0.025435  0.031378 -0.029673  \n",
       "\n",
       "[31064 rows x 50 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_test = df_new[df_new['sample']=='test']\n",
    "test_id = df_new_test['id']\n",
    "df_new_test = df_new_test.drop(['text', 'lang', 'target','sample', 'id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_train, target, \n",
    "                                                    test_size=0.2, random_state=123) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "mypipeline_lr = Pipeline([\n",
    "    ('lr', LogisticRegression())])\n",
    "\n",
    "param_grid_lr = { 'lr__penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
    "                  'lr__tol': [0.00001, 0.0001, 0.001],\n",
    "                  'lr__max_iter': [50, 100, 250, 500],\n",
    "                  'lr__solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "                  'lr__C' : [0.0001, 0.001, 0.01, 0.05, 0.1, 0.5, 0.0, 1.0]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "\n",
    "hyper_search_lr = RandomizedSearchCV(mypipeline_lr, param_grid_lr, n_iter=100, scoring='roc_auc', \n",
    "                                  cv=cv, n_jobs=4, refit=True, random_state=47,\n",
    "                                  verbose=5)\n",
    "hyper_search_lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogRes 0.9806369022492056\n"
     ]
    }
   ],
   "source": [
    "print('LogRes', hyper_search_lr.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lr__tol': 0.001, 'lr__solver': 'saga', 'lr__penalty': 'none', 'lr__max_iter': 100, 'lr__C': 1.0}\n"
     ]
    }
   ],
   "source": [
    "print(hyper_search_lr.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(tol=0.001, solver='saga', penalty = 'none', max_iter = 100, C =1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='none',\n",
       "                   random_state=None, solver='saga', tol=0.001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(df_train, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr = lr.predict_proba(df_new_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9321354806308355"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_test, predict_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_3 = []\n",
    "for i in range(len(predict_lr)):\n",
    "    score_3.append(predict_lr[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = df_new[df_new['sample']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(\n",
    "    df_test['id'],\n",
    "    score_3\n",
    "), columns=['id','target']).to_csv('predict_27-02.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(tol=0.001, solver='saga', penalty = 'none', max_iter = 100, C =1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='none',\n",
       "                   random_state=None, solver='saga', tol=0.001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(df_train_tfidf, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr_2 = lr.predict_proba(df_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_lr_1 = lr.predict_proba(df_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_tfidf = tfidf.transform(train_tfidf)\n",
    "df_test_tfidf = tfidf.transform(test_tfidf )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.22747069e-08, 9.99999988e-01],\n",
       "       [9.99999948e-01, 5.19170883e-08],\n",
       "       [9.90821909e-05, 9.99900918e-01],\n",
       "       ...,\n",
       "       [9.99903721e-01, 9.62793540e-05],\n",
       "       [7.86437733e-03, 9.92135623e-01],\n",
       "       [4.38271940e-04, 9.99561728e-01]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_lr_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_4 = []\n",
    "for i in range(len(predict_lr_1)):\n",
    "    score_4.append(predict_lr_1[i][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(\n",
    "    test_id,\n",
    "    score_4\n",
    "), columns=['id','target']).to_csv('predict_space_matrix.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_2 = pd.read_csv('predict_27-02.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.DataFrame(zip(score_3, score_4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "d['sum'] = (d[0]+d[1])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999504</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.999752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.095038</td>\n",
       "      <td>5.191709e-08</td>\n",
       "      <td>0.047519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999741</td>\n",
       "      <td>9.999009e-01</td>\n",
       "      <td>0.999821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.994797</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.997398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.766031</td>\n",
       "      <td>8.577916e-01</td>\n",
       "      <td>0.811911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31059</th>\n",
       "      <td>0.991579</td>\n",
       "      <td>9.626039e-01</td>\n",
       "      <td>0.977091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31060</th>\n",
       "      <td>0.636897</td>\n",
       "      <td>1.557382e-04</td>\n",
       "      <td>0.318526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31061</th>\n",
       "      <td>0.013173</td>\n",
       "      <td>9.627935e-05</td>\n",
       "      <td>0.006634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31062</th>\n",
       "      <td>0.078997</td>\n",
       "      <td>9.921356e-01</td>\n",
       "      <td>0.535566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31063</th>\n",
       "      <td>0.980233</td>\n",
       "      <td>9.995617e-01</td>\n",
       "      <td>0.989898</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31064 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0             1       sum\n",
       "0      0.999504  1.000000e+00  0.999752\n",
       "1      0.095038  5.191709e-08  0.047519\n",
       "2      0.999741  9.999009e-01  0.999821\n",
       "3      0.994797  1.000000e+00  0.997398\n",
       "4      0.766031  8.577916e-01  0.811911\n",
       "...         ...           ...       ...\n",
       "31059  0.991579  9.626039e-01  0.977091\n",
       "31060  0.636897  1.557382e-04  0.318526\n",
       "31061  0.013173  9.627935e-05  0.006634\n",
       "31062  0.078997  9.921356e-01  0.535566\n",
       "31063  0.980233  9.995617e-01  0.989898\n",
       "\n",
       "[31064 rows x 3 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(\n",
    "    test_id,\n",
    "    d['sum'] \n",
    "), columns=['id','target']).to_csv('predict_space_matrix_with_w2v.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
